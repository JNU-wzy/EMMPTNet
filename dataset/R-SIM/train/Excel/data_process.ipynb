{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged to row IDs: [238.0, 272.0, 711.0, 734.0, 854.0, 867.0, 953.0, 966.0, 994.0, 1002.0, 1130.0, 1143.0, 1155.0, 1782.0, 2054.0, 2147.0, 2190.0, 2383.0, 2391.0, 2480.0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 替换为您的Excel文件路径\n",
    "file_path = 'Viral_RNA_dataset_v1.xlsx'\n",
    "\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 初始化一个空的DataFrame来存储处理后的数据\n",
    "new_df = pd.DataFrame()\n",
    "\n",
    "# 记录上一个非空Entry_ID的索引和ID\n",
    "last_valid_index = None\n",
    "last_valid_id = None\n",
    "\n",
    "# 存储已合并行的ID\n",
    "merged_ids = []\n",
    "\n",
    "# 遍历DataFrame中的每一行\n",
    "for index, row in df.iterrows():\n",
    "    if pd.isnull(row['Entry_ID']):\n",
    "        # 如果Entry_ID为空，则将信息添加到上一行的相应列中\n",
    "        if last_valid_index is not None:\n",
    "            for col in df.columns:\n",
    "                # 检查目标单元格是否为空，并且当前行该列有值\n",
    "                if pd.isnull(new_df.at[last_valid_index, col]) and not pd.isnull(row[col]):\n",
    "                    new_df.at[last_valid_index, col] = row[col]\n",
    "                # 对于字符串类型的列，确保即使原始数据不是字符串，也能安全拼接\n",
    "                elif not pd.isnull(row[col]):\n",
    "                    # 将新的值转换为字符串并追加到原有数据后面\n",
    "                    new_value = str(row[col]).strip()\n",
    "                    original_value = str(new_df.at[last_valid_index, col])\n",
    "                    new_df.at[last_valid_index, col] = original_value + ' ' + new_value if original_value else new_value\n",
    "            # 记录下合并到的行的ID\n",
    "            merged_ids.append(last_valid_id)\n",
    "    else:\n",
    "        # 如果Entry_ID不为空，直接将行添加到new_df中，并更新最近的非空Entry_ID的索引和ID\n",
    "        new_df = pd.concat([new_df, pd.DataFrame([row])], ignore_index=True)\n",
    "        last_valid_index = new_df.last_valid_index()\n",
    "        last_valid_id = row['Entry_ID']\n",
    "\n",
    "# 输出所有合并到的行的ID\n",
    "print(\"Merged to row IDs:\", merged_ids)\n",
    "\n",
    "# 处理合并单元格后的NaN值\n",
    "new_df.fillna('', inplace=True)\n",
    "\n",
    "# 数据清洗\n",
    "new_df['pKd'] = new_df['pKd'].apply(lambda x: float(str(x).replace(\" \", \"\").split('\\n')[0]) if x != '' else None)\n",
    "new_df['Target_RNA_sequence'] = new_df['Target_RNA_sequence'].apply(lambda x: str(x).replace(\" \", \"\"))\n",
    "new_df['SMILES'] = new_df['SMILES'].apply(lambda x: str(x).replace(\" \", \"\"))\n",
    "\n",
    "# 保存清洗后的DataFrame到新的Excel文件\n",
    "output_file_path = 'cleaned/Viral_RNA.xlsx'  # 确保这个路径是存在的，或者自动创建目录\n",
    "new_df.to_excel(output_file_path, index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T09:15:53.115330300Z",
     "start_time": "2024-04-02T09:15:52.908467500Z"
    }
   },
   "id": "cf4439cb7b249ecc",
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +=: 'float' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[59], line 31\u001B[0m\n\u001B[0;32m     28\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m col \u001B[38;5;129;01min\u001B[39;00m df\u001B[38;5;241m.\u001B[39mcolumns:\n\u001B[0;32m     29\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(row[col], \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m pd\u001B[38;5;241m.\u001B[39mnotnull(row[col]):\n\u001B[0;32m     30\u001B[0m         \u001B[38;5;66;03m# 对字符串列，进行内容追加\u001B[39;00m\n\u001B[1;32m---> 31\u001B[0m         new_df\u001B[38;5;241m.\u001B[39mat[last_valid_index, col] \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m row[col]\u001B[38;5;241m.\u001B[39mstrip()\n\u001B[0;32m     32\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m pd\u001B[38;5;241m.\u001B[39misnull(new_df\u001B[38;5;241m.\u001B[39mat[last_valid_index, col]) \u001B[38;5;129;01mand\u001B[39;00m pd\u001B[38;5;241m.\u001B[39mnotnull(row[col]):\n\u001B[0;32m     33\u001B[0m         \u001B[38;5;66;03m# 对于其他类型的列，如果新的DataFrame中对应位置是空，则直接赋值\u001B[39;00m\n\u001B[0;32m     34\u001B[0m         new_df\u001B[38;5;241m.\u001B[39mat[last_valid_index, col] \u001B[38;5;241m=\u001B[39m row[col]\n",
      "\u001B[1;31mTypeError\u001B[0m: unsupported operand type(s) for +=: 'float' and 'str'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 替换为您的Excel文件路径\n",
    "file_path = 'Riboswitch_dataset_v1.xlsx'\n",
    "\n",
    "# 读取Excel文件\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 初始化一个新的DataFrame来存储处理后的数据\n",
    "new_df = pd.DataFrame()\n",
    "\n",
    "# 记录需要删除的行索引\n",
    "rows_to_delete = []\n",
    "\n",
    "# 记录上一个非空Entry_ID的索引\n",
    "last_valid_index = -1\n",
    "\n",
    "# 存储合并信息的字典 {非空Entry_ID: [被合并的行索引]}\n",
    "merged_info = {}\n",
    "\n",
    "# 遍历DataFrame中的每一行\n",
    "for index, row in df.iterrows():\n",
    "    if pd.isnull(row['Entry_ID']):\n",
    "        # 如果Entry_ID为空，收集该行索引以备后续删除\n",
    "        rows_to_delete.append(index)\n",
    "        if last_valid_index != -1:\n",
    "            # 将当前行的信息合并到上一个非空Entry_ID的行中\n",
    "            for col in df.columns:\n",
    "                if isinstance(row[col], str) and pd.notnull(row[col]):\n",
    "                    # 对字符串列，进行内容追加\n",
    "                    new_df.at[last_valid_index, col] += ' ' + row[col].strip()\n",
    "                elif pd.isnull(new_df.at[last_valid_index, col]) and pd.notnull(row[col]):\n",
    "                    # 对于其他类型的列，如果新的DataFrame中对应位置是空，则直接赋值\n",
    "                    new_df.at[last_valid_index, col] = row[col]\n",
    "            # 记录合并信息\n",
    "            valid_id = new_df.at[last_valid_index, 'Entry_ID']\n",
    "            if valid_id not in merged_info:\n",
    "                merged_info[valid_id] = [index]\n",
    "            else:\n",
    "                merged_info[valid_id].append(index)\n",
    "    else:\n",
    "        # 如果Entry_ID不为空，将行添加到新的DataFrame中\n",
    "        new_df = pd.concat([new_df, pd.DataFrame([row]).reset_index(drop=True)], ignore_index=True)\n",
    "        last_valid_index = new_df.last_valid_index()\n",
    "\n",
    "# 输出每个非空ID行合并了哪些行\n",
    "for valid_id, indexes in merged_info.items():\n",
    "    print(f\"Entry_ID {valid_id} merged rows: {indexes}\")\n",
    "new_df['pKd'] = new_df['pKd'].apply(lambda x: float(str(x).replace(\" \", \"\").split('\\n')[0]))\n",
    "new_df['Target_RNA_sequence'] = new_df['Target_RNA_sequence'].apply(lambda x: (str(x).replace(\" \", \"\")))\n",
    "new_df['SMILES'] = new_df['SMILES'].apply(lambda x: (str(x).replace(\" \", \"\")))\n",
    "\n",
    "output_file_path = 'cleaned/Riboswitch.xlsx'  # 指定新的文件路径和文件名\n",
    "new_df.to_excel(output_file_path, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T09:01:09.985630800Z",
     "start_time": "2024-04-02T09:01:09.901906500Z"
    }
   },
   "id": "b5875b4ae48b9545",
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry_IDs with pKd > 10: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#检查异常的pkd\n",
    "# 文件路径\n",
    "input_path = 'cleaned/miRNA.xlsx'\n",
    "\n",
    "# 读取Excel文件\n",
    "df = pd.read_excel(input_path)\n",
    "df['pKd'] = df['pKd'].apply(lambda x: float(str(x).replace(\" \", \"\").split('\\n')[0]))\n",
    "\n",
    "# 查找pKd列值大于10的所有行\n",
    "high_pkd_entries = df[df['pKd'] > 10]\n",
    "\n",
    "# 输出这些行的Entry_ID\n",
    "entry_ids = high_pkd_entries['Entry_ID'].tolist()\n",
    "print(\"Entry_IDs with pKd > 10:\", entry_ids)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T08:34:08.540979800Z",
     "start_time": "2024-04-02T08:34:08.512076400Z"
    }
   },
   "id": "7ce78e616e91221b",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255.0\n",
      "734.0\n",
      "867.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#检查是否有重复ID\n",
    "# 路径可能需要根据您的文件系统进行修改\n",
    "file_path = 'Viral_RNA_dataset_v1.xlsx'\n",
    "\n",
    "# 读取Excel文件\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 初始化空列表来存储重复的Entry_ID\n",
    "duplicate_entry_ids = []\n",
    "\n",
    "# 遍历DataFrame的行\n",
    "for i in range(1, len(df)):  # 从第二行开始，因为我们会和前一行比较\n",
    "    # 比较当前行的Entry_ID与前一行的Entry_ID\n",
    "    if df.loc[i, 'Entry_ID'] == df.loc[i-1, 'Entry_ID']:\n",
    "        # 如果它们相同，将该ID添加到列表中\n",
    "        duplicate_entry_ids.append(df.loc[i, 'Entry_ID'])\n",
    "\n",
    "# 输出重复的Entry_ID\n",
    "for entry_id in duplicate_entry_ids:\n",
    "    print(entry_id)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:59:49.539291300Z",
     "start_time": "2024-04-02T07:59:49.464540700Z"
    }
   },
   "id": "cc8cd87ca9669a6b",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8341282584155571"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
